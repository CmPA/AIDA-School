{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the target function as a quadratic function in one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function(x):\n",
    "    return -(x + 1.0)*(x - 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.0, 1.0, 101)\n",
    "y = target_function(x)\n",
    "_ = plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interval $[0, 1]$, the function is almost linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain repeatable results, we seed the random number genrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of arbitrary points in the interval $[0, 1]$ for $x$-values, and the corresponding function values with noise added.  The noise is drawn from a normal distribution with mean value 0.0 and standard deviation 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_data(func, x_min=0.0, x_max=1.0, noise=0.2, nr_points=20):\n",
    "    x = np.random.uniform(x_min, x_max, (nr_points,))\n",
    "    y = func(x) + np.random.normal(0.0, noise, x.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the data, we define a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(func, x_data, y_data, x_min=0.0, x_max=1.0):\n",
    "    _ = plt.plot(x_data, y_data, 'ro')\n",
    "    x = np.linspace(x_min, x_max, 101)\n",
    "    _ = plt.plot(x, func(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computing the fit, we generate 20 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_noisy_data(target_function, noise=0.2, nr_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(target_function, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the fit, we generate 20 additional data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = generate_noisy_data(target_function, noise=0.2, nr_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(target_function, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also generate some points outside the interval $[0.0, 1.0]$, i.e., in $[1.0, 1.5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_extra, y_extra = generate_noisy_data(target_function, x_min=1.0, x_max=1.5, noise=0.2, nr_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(target_function, x_extra, y_extra, x_min=0.0, x_max=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions to fit a polynomials with a given degree.  The degree is determined by the number of parameters given to the function, i.e.,\n",
    "$$\n",
    "    f(x) = \\sum_{i=0}^{d} p_i x^i\n",
    "$$\n",
    "Here, $d$ is the degree of the polinomial, and $\\vec{p}$ represents the coefficients of that polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func(x, *params):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal values $\\vec{p}_{\\rm opt}$ for $\\vec{p}$ are computed using the `curve_fit` function in scipy's `optimize` module.  The covariances are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_params(fit_func, xs, ys, degree):\n",
    "    p0 = [1.0]*(degree + 1)\n",
    "    p_opt, _ = curve_fit(fit_func, xs, ys, p0)\n",
    "    return p_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the optimal values of the coefficients for polynomials of degree 1 to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opts = [compute_params(fit_func, x_train, y_train, degree) for degree in range(1, 7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the results, we define a function that plots the polynomial defined by $\\vec{p}_{\\rm opt}$, as well as the points used for fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fit(fit_func, xs, ys, p_opt, x_min=0.0, x_max=1.0):\n",
    "    x = np.linspace(x_min, x_max, 101)\n",
    "    _ = plt.plot(x, fit_func(x, *p_opt))\n",
    "    _ = plt.plot(xs, ys, 'ro')\n",
    "    plt.text(0.4, 5.5, f'degree = {len(p_opt) - 1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_opt in p_opts:\n",
    "    show_fit(fit_func, x_train, y_train, p_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fits for polynomials of degree 4, 5 and 6 seem very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although visually, the polynomials fo degree 5 and 6 seem to describe the data quite well, we should verify by computing the mean square error for the validation data, i.e., the data that has not been used for performing the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(func, xs, ys, params):\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = list(range(1, len(p_opts) + 1))\n",
    "errors = [compute_errors(fit_func, x_val, y_val, p_opt) for p_opt in p_opts]\n",
    "_ = plt.plot(degrees, errors)\n",
    "_ = plt.xlabel('degree of fit')\n",
    "_ = plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, it is clear the mean square error on the validation data is minimal for polynomial of degree 2.  The polynomials of degree 3 to 6 clearly overfitted the data, i.e., are too specifically tuned towards the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean square error for the linear fit is quite large as well, but this is obviously not due to overfitting.  The model is simply not powerful enough to describe the data, which results in a large MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The wrong question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well do the fits generalize to data that was not part of the training set?  As it turns out, not all too well.  Below you see plots for data that is in the interval $[1.0, 1.5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_opt in p_opts[:3]:\n",
    "    show_fit(fit_func, x_extra, y_extra, p_opt, x_min=0.0, x_max=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = list(range(1, len(p_opts) + 1))\n",
    "errors = [compute_errors(fit_func, x_extra, y_extra, p_opt) for p_opt in p_opts]\n",
    "_ = plt.semilogy(degrees, errors)\n",
    "_ = plt.xlabel('degree of fit')\n",
    "_ = plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular training data, it turns out that the polynomial of degree 2 is not a good fit outside of the interval $[0, 1]$.  The plot below shows the target function and the fitted polynomials of degrees 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.0, 1.5, 101)\n",
    "_ = plt.plot(x, fit_func(x, *(p_opts[0])), label='fit degree 1')\n",
    "_ = plt.plot(x, target_function(x), label='target')\n",
    "_ = plt.plot(x, fit_func(x, *(p_opts[1])), label='fit degree 2')\n",
    "_ = plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
